---
title: Allen-Cahn PDE Physics-Informed Neural Network (PINN) Loss Function Error vs Time Benchmarks
author: Kirill Zubov, Zoe McCarthy, Yingbo Ma, Francesco Calisto, Valerio Pagliarino, Simone Azeglio, Luca Bottero, Emmanuel Luján, Valentin Sulzer, Ashutosh Bharambe, Nand Vinchhi, Kaushik Balakrishnan, Devesh Upadhyay, Chris Rackauckas
---

Adapted from [NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with Error Approximations](https://arxiv.org/abs/2107.09443).
Uses the [NeuralPDE.jl](https://neuralpde.sciml.ai/dev/) library from the
[SciML Scientific Machine Learning Open Source Organization](https://sciml.ai/)
for the implementation of physics-informed neural networks (PINNs) and other
science-guided AI techniques.

## Setup Code

```julia
using NeuralPDE
using Integrals, Cubature, Cuba
using ModelingToolkit, Optimization, OptimizationOptimJL, OptimizationOptimisers
using Lux, Plots
using DelimitedFiles
using QuasiMonteCarlo, Random
import ModelingToolkit: Interval, infimum, supremum

function allen_cahn(strategy, minimizer, maxIters, time_limit=3600.0)
    ## DECLARATIONS
    @parameters t x1 x2 x3 x4
    @variables u(..)

    Dt = Differential(t)
    Dxx1 = Differential(x1)^2
    Dxx2 = Differential(x2)^2
    Dxx3 = Differential(x3)^2
    Dxx4 = Differential(x4)^2

    # Discretization
    tmax = 1.0
    x1width = x2width = x3width = x4width = 1.0
    tMeshNum = x1MeshNum = x2MeshNum = x3MeshNum = x4MeshNum = 10

    dt = tmax / tMeshNum
    dx1 = x1width / x1MeshNum
    dx2 = x2width / x2MeshNum
    dx3 = x3width / x3MeshNum
    dx4 = x4width / x4MeshNum

    domains = [t ∈ Interval(0.0, tmax),
               x1 ∈ Interval(0.0, x1width),
               x2 ∈ Interval(0.0, x2width),
               x3 ∈ Interval(0.0, x3width),
               x4 ∈ Interval(0.0, x4width)]

    # Define the coordinates
    ts = 0.0:dt:tmax
    x1s = 0.0:dx1:x1width
    x2s = 0.0:dx2:x2width
    x3s = 0.0:dx3:x3width
    x4s = 0.0:dx4:x4width

    # Operators
    Δu = Dxx1(u(t,x1,x2,x3,x4)) + Dxx2(u(t,x1,x2,x3,x4)) + 
         Dxx3(u(t,x1,x2,x3,x4)) + Dxx4(u(t,x1,x2,x3,x4))

    # Equation
    eq = Dt(u(t,x1,x2,x3,x4)) - Δu - u(t,x1,x2,x3,x4) + 
         u(t,x1,x2,x3,x4)^3 ~ 0

    # Initial condition
    initialCondition = 1 / (2 + 0.4 * (x1^2 + x2^2 + x3^2 + x4^2))
    bcs = [u(0,x1,x2,x3,x4) ~ initialCondition]

    # Neural Network setup
    n = 10
    chain = Lux.Chain(
        Lux.Dense(5 => n, tanh),
        Lux.Dense(n => n, tanh),
        Lux.Dense(n => 1)
    )

    # Initialize parameters with random seed
    rng = Random.default_rng()
    Random.seed!(rng, 1234)  # For reproducibility
    ps, st = Lux.setup(rng, chain)

    # Create the PINN
    discretization = PhysicsInformedNN(
        chain,
        strategy;
        init_params = ps,
        states = st
    )

    # Setup PDE system
    @named pde_system = PDESystem(
        eq,
        bcs,
        domains,
        [t, x1, x2, x3, x4],
        [u(t, x1, x2, x3, x4)]
    )

    # Discretize
    prob = discretize(pde_system, discretization)

    # Training setup
    losses = Float64[]
    error = Float64[]
    times = Float64[]
    timeCounter = 0.0
    startTime = time_ns()

    # Callback function with time cap
    cb = function (p, l)
        try
            deltaT_s = time_ns()
            ctime = time_ns() - startTime - timeCounter
            
            push!(times, ctime / 1e9)
            push!(losses, l)
            push!(error, l)
            
            timeCounter += time_ns() - deltaT_s
            
            if (ctime / 1e9 > time_limit)
                println("Time limit of $time_limit seconds exceeded. Stopping training.")
                return true
            end
            
            println("Current loss: $l")
            return false
        catch e
            @warn "Callback error: $e"
            return false
        end
    end

    # Solve with optimization
    res = Optimization.solve(
        prob,
        minimizer;
        callback = cb,
        maxiters = maxIters
    )

    # Generate predictions
    phi = discretization.phi
    domain = [ts, x1s, x2s, x3s, x4s]
    
    u_predict = try
        [reshape([first(phi([t, x1, x2, x3, x4], res.minimizer)) 
                 for x1 in x1s, x2 in x2s, x3 in x3s, x4 in x4s],
                 (length(x1s), length(x2s), length(x3s), length(x4s))) 
                 for t in ts]
    catch e
        @warn "Prediction generation failed: $e"
        nothing
    end

    # Log the time points (ts)
    println("Time points (t) for strategy $strategy and minimizer $minimizer: ", collect(ts))

    return [error, res.minimizer, domain, times, losses]
end
```

```julia
maxIters = [(1,1,1,1,1,1,1000),(1,1,1,1,300,300,300)] #iters for ADAM/LBFGS
# maxIters = [(1,1,1,1,1,1,10),(1,1,1,3,3,3,3)] #iters for ADAM/LBFGS

strategies = [NeuralPDE.QuadratureTraining(quadrature_alg = CubaCuhre(), reltol = 1e-4, abstol = 1e-4, maxiters = 1100),
              NeuralPDE.QuadratureTraining(quadrature_alg = HCubatureJL(), reltol = 1e-4, abstol = 1e-4, maxiters = 1100, batch = 0),
              NeuralPDE.QuadratureTraining(quadrature_alg = CubatureJLh(), reltol = 1e-4, abstol = 1e-4, maxiters = 1100),
              NeuralPDE.QuadratureTraining(quadrature_alg = CubatureJLp(), reltol = 1e-4, abstol = 1e-4, maxiters = 1100),
              NeuralPDE.GridTraining(0.2),
              NeuralPDE.StochasticTraining(400 ; bcs_points= 50),
              NeuralPDE.QuasiRandomTraining(400 ; bcs_points= 50)]

strategies_short_name = ["CubaCuhre",
                        "HCubatureJL",
                        "CubatureJLh",
                        "CubatureJLp",
                        "GridTraining",
                        "StochasticTraining",
                        "QuasiRandomTraining"]

minimizers = [Optimisers.ADAM(0.005),BFGS()]
minimizers_short_name = ["ADAM","BFGS"]

# Run models
error_res =  Dict()
domains = Dict()
params_res = Dict()  #to use same params for the next run
times = Dict()
losses_res = Dict()
```

## Solve

```julia
## Convergence

for min =1:length(minimizers) # minimizer
    for strat=1:length(strategies) # strategy
          # println(string(strategies_short_name[strat], "  ", minimizers_short_name[min]))
          res = allen_cahn(strategies[strat], minimizers[min], maxIters[min][strat])
          push!(error_res, string(strat,min)     => res[1])
          push!(params_res, string(strat,min) => res[2])
          push!(domains, string(strat,min)        => res[3])
          push!(times, string(strat,min)        => res[4])
          push!(losses_res, string(strat,min)        => res[5])
    end
end
```

## Results

```julia
print("\n Plotting error vs times")
#Plotting the first strategy with the first minimizer out from the loop to initialize the canvas
current_label = string(strategies_short_name[1], " + " , minimizers_short_name[1])
error = Plots.plot(times["11"], error_res["11"], yaxis=:log10, label = current_label)#, xlims = (0,10))#legend = true)#, size=(1200,700))
plot!(error, times["21"], error_res["21"], yaxis=:log10, label = string(strategies_short_name[2], " + " , minimizers_short_name[1]))
plot!(error, times["31"], error_res["31"], yaxis=:log10, label = string(strategies_short_name[3], " + " , minimizers_short_name[1]))
plot!(error, times["41"], error_res["41"], yaxis=:log10, label = string(strategies_short_name[4], " + " , minimizers_short_name[1]))
plot!(error, times["51"], error_res["51"], yaxis=:log10, label = string(strategies_short_name[5], " + " , minimizers_short_name[1]))
plot!(error, times["61"], error_res["61"], yaxis=:log10, label = string(strategies_short_name[6], " + " , minimizers_short_name[1]))
plot!(error, times["71"], error_res["71"], yaxis=:log10, label = string(strategies_short_name[7], " + " , minimizers_short_name[1]))


plot!(error, times["12"], error_res["12"], yaxis=:log10, label = string(strategies_short_name[1], " + " , minimizers_short_name[2]))
plot!(error, times["22"], error_res["22"], yaxis=:log10, label = string(strategies_short_name[2], " + " , minimizers_short_name[2]))
plot!(error, times["32"], error_res["32"], yaxis=:log10, label = string(strategies_short_name[3], " + " , minimizers_short_name[2]))
plot!(error, times["42"], error_res["42"], yaxis=:log10, label = string(strategies_short_name[4], " + " , minimizers_short_name[2]))
plot!(error, times["52"], error_res["52"], yaxis=:log10, label = string(strategies_short_name[5], " + " , minimizers_short_name[2]))
plot!(error, times["62"], error_res["62"], yaxis=:log10, label = string(strategies_short_name[6], " + " , minimizers_short_name[2]))
plot!(error, times["72"], error_res["72"], yaxis=:log10, title = string("Allen Cahn convergence ADAM/LBFGS"), ylabel = "log(error)",xlabel = "t", label = string(strategies_short_name[7], " + " , minimizers_short_name[2]))
```

```julia, echo = false
using SciMLBenchmarks
SciMLBenchmarks.bench_footer(WEAVE_ARGS[:folder],WEAVE_ARGS[:file])
```
